# Big-Data-forecast ‚ú®

Este projeto tem como objetivo realizar previs√µes utilizando t√©cnicas de Big Data, com foco em an√°lise de vendas semanais, agrega√ß√£o de dados e cria√ß√£o de features para modelos preditivos.

---

## Estrutura do Projeto üìÇ

- **src/**: Scripts principais para carregamento, processamento e engenharia de dados.
- **notebooks/**: Jupyter Notebooks para explora√ß√£o, an√°lise e desenvolvimento dos modelos.
- **data/**: Dados brutos, processados e resultados das previs√µes.

---

## Principais Tecnologias üõ†Ô∏è

- Python (Pandas, NumPy, PySpark)
- Jupyter Notebook
- Parquet
- Big Data

---

## Como executar ‚öôÔ∏è

1.  Crie um ambiente virtual:
    ```bash
    python -m venv .venv
    ```
2.  Ative o ambiente virtual:
    ```bash
    .venv\Scripts\activate
    ```
3.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```
4.  Execute os scripts em `src/` ou os notebooks em `notebooks/`.

---

## Configura√ß√£o do Ambiente üíª

Este projeto foi desenvolvido e testado no **VS Code** e requer a configura√ß√£o correta do Java e do Python para o PySpark funcionar.

### 1. Instala√ß√£o e Configura√ß√£o do Java (JDK 17) ‚òï

O Apache Spark 3.5.1 √© compat√≠vel com o **JDK 17**. Para evitar erros, siga estas instru√ß√µes:

1.  **Baixe e instale o JDK 17:**
    - Acesse [Adoptium Temurin 17](https://adoptium.net/temurin/releases/?version=17) ou o site oficial da Oracle.
    - Instale o JDK normalmente.

2.  **Configure as vari√°veis de ambiente:**
    - No Windows, pesquise por "Vari√°veis de Ambiente do Sistema".
    - Na janela que se abrir, clique em **"Vari√°veis de Ambiente..."**.
    - Adicione ou edite a vari√°vel de sistema `JAVA_HOME` apontando para o diret√≥rio de instala√ß√£o do JDK 17.

3.  **Verifique a instala√ß√£o:**
    No terminal, execute:
    ```bash
    java -version
    echo %JAVA_HOME%
    ```
    O resultado deve mostrar a vers√£o 17 do Java e o caminho correto do JDK.

### 2. Configura√ß√£o do Ambiente Python üêç

Para garantir que o PySpark use o ambiente virtual do seu projeto, voc√™ precisa definir a vari√°vel de ambiente `PYSPARK_PYTHON` para o caminho correto do `python.exe` dentro do seu `.venv`.

**Op√ß√£o recomendada:** Defina a vari√°vel permanentemente, seguindo o mesmo processo do `JAVA_HOME`.

- **Nome da vari√°vel:** `PYSPARK_PYTHON`
- **Valor da vari√°vel:** O caminho completo para o `python.exe` dentro da sua pasta `.venv`.

**Exemplo:**

- **No Windows:**
`C:\Users\SeuUsuario\Caminho\Para\O\Projeto\.venv\Scripts\python.exe`

- **No macOS/Linux:**
`/home/seu-usuario/caminho/para/o/projeto/.venv/bin/python`

### 3. Configura√ß√£o do Hadoop (Apenas para Windows) ‚öôÔ∏è

Este passo √© crucial para usu√°rios de Windows, pois o PySpark depende de um ambiente Hadoop local para opera√ß√µes de arquivos.

1.  **Baixe os Arquivos Essenciais:**
    - Baixe os arquivos `winutils.exe` e `hadoop.dll` para a vers√£o do Hadoop compat√≠vel com o seu Spark.
    - Um reposit√≥rio comum para isso √©: `https://github.com/steveloughran/winutils/`

2.  **Crie a Pasta do Hadoop:**
    - Crie uma pasta `hadoop` na raiz do seu disco `C:` (ex: `C:\hadoop`).
    - Dentro dela, crie uma subpasta `bin` (ex: `C:\hadoop\bin`).

3.  **Mova os Arquivos:**
    - Mova `winutils.exe` e `hadoop.dll` para a pasta `C:\hadoop\bin`.

4.  **Configure a Vari√°vel de Ambiente `HADOOP_HOME`:**
    - Siga o mesmo processo de "Vari√°veis de Ambiente" usado para o `JAVA_HOME`.
    - Crie uma nova vari√°vel de sistema:
        - **Nome:** `HADOOP_HOME`
        - **Valor:** `C:\hadoop`
    - Edite a vari√°vel de sistema `Path` e adicione o caminho `C:\hadoop\bin`.

5.  **Verifique a configura√ß√£o:**
    No terminal, reinicie o ambiente e execute:
    ```bash
    echo %HADOOP_HOME%
    ```
    O resultado deve ser `C:\hadoop`.

---

## Observa√ß√µes Importantes üìå

- Os dados devem ser colocados na pasta `data/raw/` conforme a estrutura esperada pelos scripts.
- O arquivo `.gitignore` deve incluir a pasta `data/` para evitar o upload de arquivos grandes para o reposit√≥rio.

---

Projeto para estudos e experimenta√ß√£o com Big Data e previs√£o de vendas. üìà